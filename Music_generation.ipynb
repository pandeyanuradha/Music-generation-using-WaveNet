{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Music generation",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAtcgpeJ3H8R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ea550781-a054-4869-e946-84f6690edc37"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UWlnl332yE8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from music21 import *"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjscBY_o292j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#defining function to read MIDI files\n",
        "def read_midi(file):\n",
        "    \n",
        "    print(\"Loading Music File:\",file)\n",
        "    \n",
        "    notes=[]\n",
        "    notes_to_parse = None\n",
        "    \n",
        "    #parsing a midi file\n",
        "    midi = converter.parse(file)\n",
        "  \n",
        "    #grouping based on different instruments\n",
        "    s2 = instrument.partitionByInstrument(midi)\n",
        "\n",
        "    #Looping over all the instruments\n",
        "    for part in s2.parts:\n",
        "    \n",
        "        #select elements of only piano\n",
        "        if 'Piano' in str(part): \n",
        "        \n",
        "            notes_to_parse = part.recurse() \n",
        "      \n",
        "            #finding whether a particular element is note or a chord\n",
        "            for element in notes_to_parse:\n",
        "                \n",
        "                #note\n",
        "                if isinstance(element, note.Note):\n",
        "                    notes.append(str(element.pitch))\n",
        "                \n",
        "                #chord\n",
        "                elif isinstance(element, chord.Chord):\n",
        "                    notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "\n",
        "    return np.array(notes)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTtOjCar5Ru7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "outputId": "d6ad606b-aaec-40c8-dfd3-b1b8d3b8481a"
      },
      "source": [
        "#for listing down the file names\n",
        "import os\n",
        "\n",
        "#Array Processing\n",
        "import numpy as np\n",
        "\n",
        "#specify the path\n",
        "path=(r\"/content/drive/My Drive/ML Projects (Colab)/Music generation/schubert/\")\n",
        "#/content/drive/My Drive/ML Projects (Colab)/Music generation/schubert/schu_143_1.mid\n",
        "#read all the filenames\n",
        "files=[i for i in os.listdir(path) if i.endswith(\".mid\")]\n",
        "\n",
        "#reading each midi file\n",
        "notes_array = np.array([read_midi(path+i) for i in files])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Music File: /content/drive/My Drive/ML Projects (Colab)/Music generation/schubert/schubert_D850_4.mid\n",
            "Loading Music File: /content/drive/My Drive/ML Projects (Colab)/Music generation/schubert/schubert_D850_2.mid\n",
            "Loading Music File: /content/drive/My Drive/ML Projects (Colab)/Music generation/schubert/schubert_D850_1.mid\n",
            "Loading Music File: /content/drive/My Drive/ML Projects (Colab)/Music generation/schubert/schubert_D850_3.mid\n",
            "Loading Music File: /content/drive/My Drive/ML Projects (Colab)/Music generation/schubert/schub_d960_3.mid\n",
            "Loading Music File: /content/drive/My Drive/ML Projects (Colab)/Music generation/schubert/schub_d960_2.mid\n",
            "Loading Music File: /content/drive/My Drive/ML Projects (Colab)/Music generation/schubert/schumm-3.mid\n",
            "Loading Music File: /content/drive/My Drive/ML Projects (Colab)/Music generation/schubert/schuim-4.mid\n",
            "Loading Music File: /content/drive/My Drive/ML Projects (Colab)/Music generation/schubert/schub_d760_3.mid\n",
            "Loading Music File: /content/drive/My Drive/ML Projects (Colab)/Music generation/schubert/schubert_D935_1.mid\n",
            "Loading Music File: /content/drive/My Drive/ML Projects (Colab)/Music generation/schubert/schub_d960_1.mid\n",
            "Loading Music File: /content/drive/My Drive/ML Projects (Colab)/Music generation/schubert/schub_d760_4.mid\n",
            "Loading Music File: /content/drive/My Drive/ML Projects (Colab)/Music generation/schubert/schumm-1.mid\n",
            "Loading Music File: /content/drive/My Drive/ML Projects (Colab)/Music generation/schubert/schubert_D935_4.mid\n",
            "Loading Music File: /content/drive/My Drive/ML Projects (Colab)/Music generation/schubert/schubert_D935_3.mid\n",
            "Loading Music File: /content/drive/My Drive/ML Projects (Colab)/Music generation/schubert/schumm-2.mid\n",
            "Loading Music File: /content/drive/My Drive/ML Projects (Colab)/Music generation/schubert/schub_d760_1.mid\n",
            "Loading Music File: /content/drive/My Drive/ML Projects (Colab)/Music generation/schubert/schuim-3.mid\n",
            "Loading Music File: /content/drive/My Drive/ML Projects (Colab)/Music generation/schubert/schubert_D935_2.mid\n",
            "Loading Music File: /content/drive/My Drive/ML Projects (Colab)/Music generation/schubert/schuim-2.mid\n",
            "Loading Music File: /content/drive/My Drive/ML Projects (Colab)/Music generation/schubert/schub_d960_4.mid\n",
            "Loading Music File: /content/drive/My Drive/ML Projects (Colab)/Music generation/schubert/schuim-1.mid\n",
            "Loading Music File: /content/drive/My Drive/ML Projects (Colab)/Music generation/schubert/schub_d760_2.mid\n",
            "Loading Music File: /content/drive/My Drive/ML Projects (Colab)/Music generation/schubert/schumm-5.mid\n",
            "Loading Music File: /content/drive/My Drive/ML Projects (Colab)/Music generation/schubert/schu_143_2.mid\n",
            "Loading Music File: /content/drive/My Drive/ML Projects (Colab)/Music generation/schubert/schumm-6.mid\n",
            "Loading Music File: /content/drive/My Drive/ML Projects (Colab)/Music generation/schubert/schumm-4.mid\n",
            "Loading Music File: /content/drive/My Drive/ML Projects (Colab)/Music generation/schubert/schu_143_3.mid\n",
            "Loading Music File: /content/drive/My Drive/ML Projects (Colab)/Music generation/schubert/schu_143_1.mid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c59t7MSV5THw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3ba9035d-2755-4f50-9414-aaaece9ea376"
      },
      "source": [
        "notes_ = [element for note_ in notes_array for element in note_]\n",
        "\n",
        "#No. of unique notes\n",
        "unique_notes = list(set(notes_))\n",
        "print(len(unique_notes))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "304\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eL6ymNJn5TEp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "a2b5de45-a5dc-47d9-85b5-d4faa0e1c08d"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "#computing frequency of each note\n",
        "freq = dict(Counter(notes_))\n",
        "\n",
        "#library for visualiation\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#consider only the frequencies\n",
        "no=[count for _,count in freq.items()]\n",
        "\n",
        "#set the figure size\n",
        "plt.figure(figsize=(5,5))\n",
        "\n",
        "#plot\n",
        "plt.hist(no)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([187.,  41.,  26.,  11.,   6.,   9.,  12.,   6.,   3.,   3.]),\n",
              " array([1.0000e+00, 1.4790e+02, 2.9480e+02, 4.4170e+02, 5.8860e+02,\n",
              "        7.3550e+02, 8.8240e+02, 1.0293e+03, 1.1762e+03, 1.3231e+03,\n",
              "        1.4700e+03]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 319,
              "height": 302
            },
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLelmrS2UupF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3731b4ab-c361-4cf9-e7ac-30e0af0ed6e8"
      },
      "source": [
        "frequent_notes = [note_ for note_, count in freq.items() if count>=50]\n",
        "print(len(frequent_notes))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "167\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQSs4h5aUvqE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_music=[]\n",
        "\n",
        "for notes in notes_array:\n",
        "    temp=[]\n",
        "    for note_ in notes:\n",
        "        if note_ in frequent_notes:\n",
        "            temp.append(note_)            \n",
        "    new_music.append(temp)\n",
        "    \n",
        "new_music = np.array(new_music)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRNazKLdUvmu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "no_of_timesteps = 32\n",
        "x = []\n",
        "y = []\n",
        "\n",
        "for note_ in new_music:\n",
        "    for i in range(0, len(note_) - no_of_timesteps, 1):\n",
        "        \n",
        "        #preparing input and output sequences\n",
        "        input_ = note_[i:i + no_of_timesteps]\n",
        "        output = note_[i + no_of_timesteps]\n",
        "        \n",
        "        x.append(input_)\n",
        "        y.append(output)\n",
        "        \n",
        "x=np.array(x)\n",
        "y=np.array(y)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ze-pfQRLUvis",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unique_x = list(set(x.ravel()))\n",
        "x_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_x))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5icS86MUull",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_seq=[]\n",
        "for i in x:\n",
        "    temp=[]\n",
        "    for j in i:\n",
        "        #assigning unique integer to every note\n",
        "        temp.append(x_note_to_int[j])\n",
        "    x_seq.append(temp)\n",
        "    \n",
        "x_seq = np.array(x_seq)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4S8ykS_AUuiY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unique_y = list(set(y))\n",
        "y_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_y)) \n",
        "y_seq=np.array([y_note_to_int[i] for i in y])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEDFnHlTUue_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_tr, x_val, y_tr, y_val = train_test_split(x_seq,y_seq,test_size=0.2,random_state=0)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Kf-Ls6VUual",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lstm():\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(128,return_sequences=True))\n",
        "  model.add(LSTM(128))\n",
        "  model.add(Dense(256))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dense(n_vocab))\n",
        "  model.add(Activation('softmax'))\n",
        "  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
        "  return model"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyaQg70NUuWI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "e191bb1c-f362-4215-95e0-32508112c22b"
      },
      "source": [
        "from keras.layers import *\n",
        "from keras.models import *\n",
        "from keras.callbacks import *\n",
        "import keras.backend as K\n",
        "\n",
        "K.clear_session()\n",
        "model = Sequential()\n",
        "    \n",
        "#embedding layer\n",
        "model.add(Embedding(len(unique_x), 100, input_length=32,trainable=True)) \n",
        "\n",
        "model.add(Conv1D(64,3, padding='causal',activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(MaxPool1D(2))\n",
        "    \n",
        "model.add(Conv1D(128,3,activation='relu',dilation_rate=2,padding='causal'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(MaxPool1D(2))\n",
        "\n",
        "model.add(Conv1D(256,3,activation='relu',dilation_rate=4,padding='causal'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(MaxPool1D(2))\n",
        "          \n",
        "#model.add(Conv1D(256,5,activation='relu'))    \n",
        "model.add(GlobalMaxPool1D())\n",
        "    \n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(len(unique_y), activation='softmax'))\n",
        "    \n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 32, 100)           16700     \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 32, 64)            19264     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32, 64)            0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 16, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 16, 128)           24704     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 16, 128)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 8, 128)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 8, 256)            98560     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 8, 256)            0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 4, 256)            0         \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 167)               42919     \n",
            "=================================================================\n",
            "Total params: 267,939\n",
            "Trainable params: 267,939\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-t3p_9GWOdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mc=ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True,verbose=1)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAeNSw-kWOY_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f76052c4-751e-4d02-ca93-e98fbe65ee8a"
      },
      "source": [
        "history = model.fit(np.array(x_tr),np.array(y_tr),batch_size=128,epochs=50, validation_data=(np.array(x_val),np.array(y_val)),verbose=1, callbacks=[mc])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "403/403 [==============================] - ETA: 0s - loss: 4.3597\n",
            "Epoch 00001: val_loss improved from inf to 4.04473, saving model to best_model.h5\n",
            "403/403 [==============================] - 3s 7ms/step - loss: 4.3597 - val_loss: 4.0447\n",
            "Epoch 2/50\n",
            "395/403 [============================>.] - ETA: 0s - loss: 3.8068\n",
            "Epoch 00002: val_loss improved from 4.04473 to 3.84167, saving model to best_model.h5\n",
            "403/403 [==============================] - 3s 6ms/step - loss: 3.8045 - val_loss: 3.8417\n",
            "Epoch 3/50\n",
            "397/403 [============================>.] - ETA: 0s - loss: 3.6293\n",
            "Epoch 00003: val_loss improved from 3.84167 to 3.69192, saving model to best_model.h5\n",
            "403/403 [==============================] - 3s 6ms/step - loss: 3.6294 - val_loss: 3.6919\n",
            "Epoch 4/50\n",
            "394/403 [============================>.] - ETA: 0s - loss: 3.5041\n",
            "Epoch 00004: val_loss improved from 3.69192 to 3.58552, saving model to best_model.h5\n",
            "403/403 [==============================] - 3s 6ms/step - loss: 3.5018 - val_loss: 3.5855\n",
            "Epoch 5/50\n",
            "397/403 [============================>.] - ETA: 0s - loss: 3.4043\n",
            "Epoch 00005: val_loss improved from 3.58552 to 3.51311, saving model to best_model.h5\n",
            "403/403 [==============================] - 3s 6ms/step - loss: 3.4054 - val_loss: 3.5131\n",
            "Epoch 6/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 3.3156\n",
            "Epoch 00006: val_loss improved from 3.51311 to 3.47131, saving model to best_model.h5\n",
            "403/403 [==============================] - 3s 6ms/step - loss: 3.3157 - val_loss: 3.4713\n",
            "Epoch 7/50\n",
            "395/403 [============================>.] - ETA: 0s - loss: 3.2470\n",
            "Epoch 00007: val_loss improved from 3.47131 to 3.38982, saving model to best_model.h5\n",
            "403/403 [==============================] - 3s 6ms/step - loss: 3.2466 - val_loss: 3.3898\n",
            "Epoch 8/50\n",
            "396/403 [============================>.] - ETA: 0s - loss: 3.1804\n",
            "Epoch 00008: val_loss improved from 3.38982 to 3.32855, saving model to best_model.h5\n",
            "403/403 [==============================] - 3s 6ms/step - loss: 3.1795 - val_loss: 3.3286\n",
            "Epoch 9/50\n",
            "398/403 [============================>.] - ETA: 0s - loss: 3.1177\n",
            "Epoch 00009: val_loss improved from 3.32855 to 3.30465, saving model to best_model.h5\n",
            "403/403 [==============================] - 2s 6ms/step - loss: 3.1187 - val_loss: 3.3047\n",
            "Epoch 10/50\n",
            "397/403 [============================>.] - ETA: 0s - loss: 3.0667\n",
            "Epoch 00010: val_loss improved from 3.30465 to 3.24748, saving model to best_model.h5\n",
            "403/403 [==============================] - 3s 6ms/step - loss: 3.0662 - val_loss: 3.2475\n",
            "Epoch 11/50\n",
            "401/403 [============================>.] - ETA: 0s - loss: 3.0178\n",
            "Epoch 00011: val_loss did not improve from 3.24748\n",
            "403/403 [==============================] - 2s 6ms/step - loss: 3.0172 - val_loss: 3.2503\n",
            "Epoch 12/50\n",
            "397/403 [============================>.] - ETA: 0s - loss: 2.9704\n",
            "Epoch 00012: val_loss improved from 3.24748 to 3.18241, saving model to best_model.h5\n",
            "403/403 [==============================] - 3s 6ms/step - loss: 2.9706 - val_loss: 3.1824\n",
            "Epoch 13/50\n",
            "403/403 [==============================] - ETA: 0s - loss: 2.9265\n",
            "Epoch 00013: val_loss improved from 3.18241 to 3.15101, saving model to best_model.h5\n",
            "403/403 [==============================] - 3s 6ms/step - loss: 2.9265 - val_loss: 3.1510\n",
            "Epoch 14/50\n",
            "394/403 [============================>.] - ETA: 0s - loss: 2.8902\n",
            "Epoch 00014: val_loss improved from 3.15101 to 3.13435, saving model to best_model.h5\n",
            "403/403 [==============================] - 3s 6ms/step - loss: 2.8912 - val_loss: 3.1343\n",
            "Epoch 15/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 2.8573\n",
            "Epoch 00015: val_loss improved from 3.13435 to 3.12909, saving model to best_model.h5\n",
            "403/403 [==============================] - 3s 6ms/step - loss: 2.8576 - val_loss: 3.1291\n",
            "Epoch 16/50\n",
            "394/403 [============================>.] - ETA: 0s - loss: 2.8202\n",
            "Epoch 00016: val_loss improved from 3.12909 to 3.08332, saving model to best_model.h5\n",
            "403/403 [==============================] - 3s 6ms/step - loss: 2.8211 - val_loss: 3.0833\n",
            "Epoch 17/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 2.7862\n",
            "Epoch 00017: val_loss improved from 3.08332 to 3.06594, saving model to best_model.h5\n",
            "403/403 [==============================] - 2s 6ms/step - loss: 2.7863 - val_loss: 3.0659\n",
            "Epoch 18/50\n",
            "396/403 [============================>.] - ETA: 0s - loss: 2.7588\n",
            "Epoch 00018: val_loss improved from 3.06594 to 3.04190, saving model to best_model.h5\n",
            "403/403 [==============================] - 3s 6ms/step - loss: 2.7605 - val_loss: 3.0419\n",
            "Epoch 19/50\n",
            "399/403 [============================>.] - ETA: 0s - loss: 2.7334\n",
            "Epoch 00019: val_loss improved from 3.04190 to 3.02423, saving model to best_model.h5\n",
            "403/403 [==============================] - 2s 6ms/step - loss: 2.7329 - val_loss: 3.0242\n",
            "Epoch 20/50\n",
            "396/403 [============================>.] - ETA: 0s - loss: 2.7012\n",
            "Epoch 00020: val_loss improved from 3.02423 to 2.99782, saving model to best_model.h5\n",
            "403/403 [==============================] - 3s 6ms/step - loss: 2.7019 - val_loss: 2.9978\n",
            "Epoch 21/50\n",
            "396/403 [============================>.] - ETA: 0s - loss: 2.6839\n",
            "Epoch 00021: val_loss improved from 2.99782 to 2.99696, saving model to best_model.h5\n",
            "403/403 [==============================] - 2s 6ms/step - loss: 2.6837 - val_loss: 2.9970\n",
            "Epoch 22/50\n",
            "395/403 [============================>.] - ETA: 0s - loss: 2.6623\n",
            "Epoch 00022: val_loss improved from 2.99696 to 2.98092, saving model to best_model.h5\n",
            "403/403 [==============================] - 2s 6ms/step - loss: 2.6609 - val_loss: 2.9809\n",
            "Epoch 23/50\n",
            "395/403 [============================>.] - ETA: 0s - loss: 2.6370\n",
            "Epoch 00023: val_loss improved from 2.98092 to 2.95734, saving model to best_model.h5\n",
            "403/403 [==============================] - 3s 6ms/step - loss: 2.6380 - val_loss: 2.9573\n",
            "Epoch 24/50\n",
            "395/403 [============================>.] - ETA: 0s - loss: 2.6146\n",
            "Epoch 00024: val_loss did not improve from 2.95734\n",
            "403/403 [==============================] - 2s 6ms/step - loss: 2.6158 - val_loss: 2.9645\n",
            "Epoch 25/50\n",
            "394/403 [============================>.] - ETA: 0s - loss: 2.5971\n",
            "Epoch 00025: val_loss improved from 2.95734 to 2.94299, saving model to best_model.h5\n",
            "403/403 [==============================] - 3s 6ms/step - loss: 2.5981 - val_loss: 2.9430\n",
            "Epoch 26/50\n",
            "394/403 [============================>.] - ETA: 0s - loss: 2.5840\n",
            "Epoch 00026: val_loss improved from 2.94299 to 2.93706, saving model to best_model.h5\n",
            "403/403 [==============================] - 3s 6ms/step - loss: 2.5840 - val_loss: 2.9371\n",
            "Epoch 27/50\n",
            "403/403 [==============================] - ETA: 0s - loss: 2.5719\n",
            "Epoch 00027: val_loss improved from 2.93706 to 2.92867, saving model to best_model.h5\n",
            "403/403 [==============================] - 3s 6ms/step - loss: 2.5719 - val_loss: 2.9287\n",
            "Epoch 28/50\n",
            "400/403 [============================>.] - ETA: 0s - loss: 2.5535\n",
            "Epoch 00028: val_loss improved from 2.92867 to 2.90408, saving model to best_model.h5\n",
            "403/403 [==============================] - 2s 6ms/step - loss: 2.5528 - val_loss: 2.9041\n",
            "Epoch 29/50\n",
            "398/403 [============================>.] - ETA: 0s - loss: 2.5340\n",
            "Epoch 00029: val_loss improved from 2.90408 to 2.90143, saving model to best_model.h5\n",
            "403/403 [==============================] - 3s 6ms/step - loss: 2.5340 - val_loss: 2.9014\n",
            "Epoch 30/50\n",
            "399/403 [============================>.] - ETA: 0s - loss: 2.5242\n",
            "Epoch 00030: val_loss did not improve from 2.90143\n",
            "403/403 [==============================] - 2s 6ms/step - loss: 2.5252 - val_loss: 2.9027\n",
            "Epoch 31/50\n",
            "394/403 [============================>.] - ETA: 0s - loss: 2.5114\n",
            "Epoch 00031: val_loss improved from 2.90143 to 2.88980, saving model to best_model.h5\n",
            "403/403 [==============================] - 2s 6ms/step - loss: 2.5141 - val_loss: 2.8898\n",
            "Epoch 32/50\n",
            "397/403 [============================>.] - ETA: 0s - loss: 2.4918\n",
            "Epoch 00032: val_loss improved from 2.88980 to 2.87131, saving model to best_model.h5\n",
            "403/403 [==============================] - 2s 6ms/step - loss: 2.4923 - val_loss: 2.8713\n",
            "Epoch 33/50\n",
            "396/403 [============================>.] - ETA: 0s - loss: 2.4863\n",
            "Epoch 00033: val_loss improved from 2.87131 to 2.86180, saving model to best_model.h5\n",
            "403/403 [==============================] - 2s 6ms/step - loss: 2.4867 - val_loss: 2.8618\n",
            "Epoch 34/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 2.4744\n",
            "Epoch 00034: val_loss improved from 2.86180 to 2.84724, saving model to best_model.h5\n",
            "403/403 [==============================] - 3s 6ms/step - loss: 2.4742 - val_loss: 2.8472\n",
            "Epoch 35/50\n",
            "403/403 [==============================] - ETA: 0s - loss: 2.4655\n",
            "Epoch 00035: val_loss improved from 2.84724 to 2.84489, saving model to best_model.h5\n",
            "403/403 [==============================] - 3s 6ms/step - loss: 2.4655 - val_loss: 2.8449\n",
            "Epoch 36/50\n",
            "398/403 [============================>.] - ETA: 0s - loss: 2.4564\n",
            "Epoch 00036: val_loss did not improve from 2.84489\n",
            "403/403 [==============================] - 3s 6ms/step - loss: 2.4567 - val_loss: 2.8476\n",
            "Epoch 37/50\n",
            "394/403 [============================>.] - ETA: 0s - loss: 2.4440\n",
            "Epoch 00037: val_loss did not improve from 2.84489\n",
            "403/403 [==============================] - 2s 6ms/step - loss: 2.4444 - val_loss: 2.8463\n",
            "Epoch 38/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 2.4379\n",
            "Epoch 00038: val_loss improved from 2.84489 to 2.83236, saving model to best_model.h5\n",
            "403/403 [==============================] - 3s 6ms/step - loss: 2.4377 - val_loss: 2.8324\n",
            "Epoch 39/50\n",
            "403/403 [==============================] - ETA: 0s - loss: 2.4243\n",
            "Epoch 00039: val_loss did not improve from 2.83236\n",
            "403/403 [==============================] - 2s 6ms/step - loss: 2.4243 - val_loss: 2.8361\n",
            "Epoch 40/50\n",
            "395/403 [============================>.] - ETA: 0s - loss: 2.4114\n",
            "Epoch 00040: val_loss improved from 2.83236 to 2.81644, saving model to best_model.h5\n",
            "403/403 [==============================] - 3s 6ms/step - loss: 2.4116 - val_loss: 2.8164\n",
            "Epoch 41/50\n",
            "394/403 [============================>.] - ETA: 0s - loss: 2.4003\n",
            "Epoch 00041: val_loss improved from 2.81644 to 2.80871, saving model to best_model.h5\n",
            "403/403 [==============================] - 3s 6ms/step - loss: 2.4004 - val_loss: 2.8087\n",
            "Epoch 42/50\n",
            "397/403 [============================>.] - ETA: 0s - loss: 2.3889\n",
            "Epoch 00042: val_loss did not improve from 2.80871\n",
            "403/403 [==============================] - 2s 6ms/step - loss: 2.3916 - val_loss: 2.8128\n",
            "Epoch 43/50\n",
            "396/403 [============================>.] - ETA: 0s - loss: 2.3806\n",
            "Epoch 00043: val_loss improved from 2.80871 to 2.80035, saving model to best_model.h5\n",
            "403/403 [==============================] - 3s 6ms/step - loss: 2.3816 - val_loss: 2.8003\n",
            "Epoch 44/50\n",
            "398/403 [============================>.] - ETA: 0s - loss: 2.3791\n",
            "Epoch 00044: val_loss improved from 2.80035 to 2.79532, saving model to best_model.h5\n",
            "403/403 [==============================] - 2s 6ms/step - loss: 2.3793 - val_loss: 2.7953\n",
            "Epoch 45/50\n",
            "396/403 [============================>.] - ETA: 0s - loss: 2.3713\n",
            "Epoch 00045: val_loss did not improve from 2.79532\n",
            "403/403 [==============================] - 2s 6ms/step - loss: 2.3723 - val_loss: 2.8041\n",
            "Epoch 46/50\n",
            "399/403 [============================>.] - ETA: 0s - loss: 2.3634\n",
            "Epoch 00046: val_loss improved from 2.79532 to 2.76396, saving model to best_model.h5\n",
            "403/403 [==============================] - 3s 6ms/step - loss: 2.3637 - val_loss: 2.7640\n",
            "Epoch 47/50\n",
            "401/403 [============================>.] - ETA: 0s - loss: 2.3597\n",
            "Epoch 00047: val_loss did not improve from 2.76396\n",
            "403/403 [==============================] - 2s 6ms/step - loss: 2.3593 - val_loss: 2.7758\n",
            "Epoch 48/50\n",
            "398/403 [============================>.] - ETA: 0s - loss: 2.3479\n",
            "Epoch 00048: val_loss did not improve from 2.76396\n",
            "403/403 [==============================] - 2s 6ms/step - loss: 2.3493 - val_loss: 2.7775\n",
            "Epoch 49/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 2.3352\n",
            "Epoch 00049: val_loss did not improve from 2.76396\n",
            "403/403 [==============================] - 2s 6ms/step - loss: 2.3358 - val_loss: 2.7644\n",
            "Epoch 50/50\n",
            "397/403 [============================>.] - ETA: 0s - loss: 2.3295\n",
            "Epoch 00050: val_loss did not improve from 2.76396\n",
            "403/403 [==============================] - 2s 6ms/step - loss: 2.3318 - val_loss: 2.7664\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTK4-fiRWOUf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('best_model.h5')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixp1cQLsWOPo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5e103c85-4307-4cba-82c0-244e82991b0e"
      },
      "source": [
        "import random\n",
        "ind = np.random.randint(0,len(x_val)-1)\n",
        "\n",
        "random_music = x_val[ind]\n",
        "\n",
        "predictions=[]\n",
        "for i in range(10):\n",
        "\n",
        "    random_music = random_music.reshape(1,no_of_timesteps)\n",
        "\n",
        "    prob  = model.predict(random_music)[0]\n",
        "    y_pred= np.argmax(prob,axis=0)\n",
        "    predictions.append(y_pred)\n",
        "\n",
        "    random_music = np.insert(random_music[0],len(random_music[0]),y_pred)\n",
        "    random_music = random_music[1:]\n",
        "    \n",
        "print(predictions)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[104, 104, 104, 104, 104, 104, 104, 104, 104, 84]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PH3uUDiWOJc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_int_to_note = dict((number, note_) for number, note_ in enumerate(unique_x)) \n",
        "predicted_notes = [x_int_to_note[i] for i in predictions]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5O-Em5Xq3sP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_to_midi(prediction_output):\n",
        "   \n",
        "    offset = 0\n",
        "    output_notes = []\n",
        "\n",
        "    # create note and chord objects based on the values generated by the model\n",
        "    for pattern in prediction_output:\n",
        "        \n",
        "        # pattern is a chord\n",
        "        if ('.' in pattern) or pattern.isdigit():\n",
        "            notes_in_chord = pattern.split('.')\n",
        "            notes = []\n",
        "            for current_note in notes_in_chord:\n",
        "                \n",
        "                cn=int(current_note)\n",
        "                new_note = note.Note(cn)\n",
        "                new_note.storedInstrument = instrument.Piano()\n",
        "                notes.append(new_note)\n",
        "                \n",
        "            new_chord = chord.Chord(notes)\n",
        "            new_chord.offset = offset\n",
        "            output_notes.append(new_chord)\n",
        "            \n",
        "        # pattern is a note\n",
        "        else:\n",
        "            \n",
        "            new_note = note.Note(pattern)\n",
        "            new_note.offset = offset\n",
        "            new_note.storedInstrument = instrument.Piano()\n",
        "            output_notes.append(new_note)\n",
        "\n",
        "        # increase offset each iteration so that notes do not stack\n",
        "        offset += 1\n",
        "    midi_stream = stream.Stream(output_notes)\n",
        "    midi_stream.write('midi', fp='music.mid')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vr7Otg5-q3pf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "convert_to_midi(predicted_notes)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5Ia85pKq3m3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EM7VVB3hq3kO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 22,
      "outputs": []
    }
  ]
}